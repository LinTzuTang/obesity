{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/obesity')\n",
    "from obesity.snp_encoding_traintest_split import snp_fast_encoding_and_labeling_p\n",
    "from obesity.model import dense_model\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obesity_snp_data_path = '/home/obesity/snp_data/snp_data_20210611_1/train_001_snp_obesity_SNP_12234_#_4274.tsv'\n",
    "train_normal_snp_data_path = '/home/obesity/snp_data/snp_data_20210611_1/train_001_snp_normal_SNP_12234_#_32609.tsv'\n",
    "valid_obesity_snp_data_path = '/home/obesity/snp_data/snp_data_20210611_1/valid_001_snp_obesity_SNP_12234_#_506.tsv'\n",
    "valid_normal_snp_data_path = '/home/obesity/snp_data/snp_data_20210611_1/valid_001_snp_normal_SNP_12234_#_3648.tsv'\n",
    "test_obesity_snp_data_path = '/home/obesity/snp_data/snp_data_20210611_1/test_001_snp_obesity_SNP_12234_#_61.tsv'\n",
    "test_normal_snp_data_path = '/home/obesity/snp_data/snp_data_20210611_1/test_001_snp_normal_SNP_12234_#_383.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = snp_fast_encoding_and_labeling_p(train_normal_snp_data_path, train_obesity_snp_data_path,balance=False,phenotype=False)\n",
    "valid_data, valid_labels = snp_fast_encoding_and_labeling_p(valid_normal_snp_data_path, valid_obesity_snp_data_path,balance=False,phenotype=False)\n",
    "#test_data, test_labels = snp_fast_encoding_and_labeling(test_normal_snp_data_path, test_obesity_snp_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "train_data_onehot = to_categorical(train_data)\n",
    "valid_data_onehot = to_categorical(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4154, 12234, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate, BatchNormalization\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense, Dropout,Softmax\n",
    "from tensorflow.keras.layers import Embedding,Reshape\n",
    "from tensorflow.keras.layers import Input,Flatten\n",
    "from tensorflow.keras.layers import LeakyReLU,RepeatVector\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self,train_data):\n",
    "        super().__init__()\n",
    "        n_cols = train_data.shape[1]\n",
    "        input_ = Input(shape=(n_cols,11))\n",
    "        #Input layer\n",
    "        # e = Embedding(11, 8)(input_)\n",
    "        e = Flatten()(input_)\n",
    "        #Encodeing\n",
    "        x = BatchNormalization(center=False,scale=False)(LeakyReLU()(Dense(256)(e)))\n",
    "        embedding = BatchNormalization(center=False,scale=False,name='embedding')(LeakyReLU()(Dense(128)(x)))\n",
    "        #Decoding\n",
    "        x = BatchNormalization(center=False,scale=False)(LeakyReLU()(Dense(256)(embedding)))\n",
    "        x = Dense(n_cols*11, activation='linear')(x)\n",
    "        x = Reshape((n_cols,11))(x)\n",
    "        output_ = Softmax(axis=2)(x)\n",
    "        self.model = tf.keras.Model(input_,output_)\n",
    "        self.build((1,n_cols,11))\n",
    "    \n",
    "    def summary(self,show_detail=False):\n",
    "        if show_detail:\n",
    "            return self.model.summary()\n",
    "        else: \n",
    "            return super().summary()\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.model(inputs,training)     \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 12234, 11)]       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 134574)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               34451200  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "embedding (BatchNormalizatio (None, 128)               256       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 134574)            34585518  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 12234, 11)         0         \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 12234, 11)         0         \n",
      "=================================================================\n",
      "Total params: 69,103,918\n",
      "Trainable params: 69,102,638\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "e = Autoencoder(train_data_onehot)\n",
    "e.summary(show_detail=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights_filepath = 'model/autoencoder_991_001.h5'\n",
    "reduce_lr = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                                              patience=50,verbose=1)\n",
    "e_s = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                      min_delta=0,\n",
    "                                      patience=150,\n",
    "                                      verbose=0, mode='min')\n",
    "saveBestModel = tensorflow.keras.callbacks.ModelCheckpoint(best_weights_filepath, \n",
    "                                                        monitor='val_loss', \n",
    "                                                        verbose=1, \n",
    "                                                        save_best_only=True, \n",
    "                                                        mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 2.3003\n",
      "Epoch 00001: val_loss improved from inf to 2.19807, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 120s 16ms/step - loss: 2.3003 - val_loss: 2.1981\n",
      "Epoch 2/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 2.1603\n",
      "Epoch 00002: val_loss improved from 2.19807 to 2.06807, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 117s 16ms/step - loss: 2.1603 - val_loss: 2.0681\n",
      "Epoch 3/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 2.0452\n",
      "Epoch 00003: val_loss improved from 2.06807 to 1.96153, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 2.0452 - val_loss: 1.9615\n",
      "Epoch 4/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 1.9388\n",
      "Epoch 00004: val_loss improved from 1.96153 to 1.85257, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 117s 16ms/step - loss: 1.9388 - val_loss: 1.8526\n",
      "Epoch 5/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 1.8383\n",
      "Epoch 00005: val_loss improved from 1.85257 to 1.75285, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 117s 16ms/step - loss: 1.8383 - val_loss: 1.7528\n",
      "Epoch 6/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 1.7432\n",
      "Epoch 00006: val_loss improved from 1.75285 to 1.65949, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 117s 16ms/step - loss: 1.7432 - val_loss: 1.6595\n",
      "Epoch 7/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 1.6515\n",
      "Epoch 00007: val_loss improved from 1.65949 to 1.57197, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 117s 16ms/step - loss: 1.6515 - val_loss: 1.5720\n",
      "Epoch 8/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 1.5654\n",
      "Epoch 00008: val_loss improved from 1.57197 to 1.48758, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 118s 16ms/step - loss: 1.5654 - val_loss: 1.4876\n",
      "Epoch 9/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 1.4831\n",
      "Epoch 00009: val_loss improved from 1.48758 to 1.40704, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 16ms/step - loss: 1.4831 - val_loss: 1.4070\n",
      "Epoch 10/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 1.4058\n",
      "Epoch 00010: val_loss improved from 1.40704 to 1.33372, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 16ms/step - loss: 1.4058 - val_loss: 1.3337\n",
      "Epoch 11/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 1.3327\n",
      "Epoch 00011: val_loss improved from 1.33372 to 1.26226, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 1.3327 - val_loss: 1.2623\n",
      "Epoch 12/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 1.2640\n",
      "Epoch 00012: val_loss improved from 1.26226 to 1.19846, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 120s 16ms/step - loss: 1.2640 - val_loss: 1.1985\n",
      "Epoch 13/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 1.1991\n",
      "Epoch 00013: val_loss improved from 1.19846 to 1.13537, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 1.1990 - val_loss: 1.1354\n",
      "Epoch 14/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 1.1387\n",
      "Epoch 00014: val_loss improved from 1.13537 to 1.07804, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 17ms/step - loss: 1.1387 - val_loss: 1.0780\n",
      "Epoch 15/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 1.0828\n",
      "Epoch 00015: val_loss improved from 1.07804 to 1.02458, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 17ms/step - loss: 1.0828 - val_loss: 1.0246\n",
      "Epoch 16/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 1.0303\n",
      "Epoch 00016: val_loss improved from 1.02458 to 0.97479, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 16ms/step - loss: 1.0303 - val_loss: 0.9748\n",
      "Epoch 17/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.9821\n",
      "Epoch 00017: val_loss improved from 0.97479 to 0.92933, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 17ms/step - loss: 0.9821 - val_loss: 0.9293\n",
      "Epoch 18/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.9379\n",
      "Epoch 00018: val_loss improved from 0.92933 to 0.88729, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 17ms/step - loss: 0.9379 - val_loss: 0.8873\n",
      "Epoch 19/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.8971\n",
      "Epoch 00019: val_loss improved from 0.88729 to 0.84880, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 117s 16ms/step - loss: 0.8971 - val_loss: 0.8488\n",
      "Epoch 20/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.8601\n",
      "Epoch 00020: val_loss improved from 0.84880 to 0.81445, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 115s 16ms/step - loss: 0.8601 - val_loss: 0.8144\n",
      "Epoch 21/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.8264\n",
      "Epoch 00021: val_loss improved from 0.81445 to 0.78311, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 115s 16ms/step - loss: 0.8264 - val_loss: 0.7831\n",
      "Epoch 22/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.7954\n",
      "Epoch 00022: val_loss improved from 0.78311 to 0.75508, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 114s 15ms/step - loss: 0.7954 - val_loss: 0.7551\n",
      "Epoch 23/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.7679\n",
      "Epoch 00023: val_loss improved from 0.75508 to 0.72922, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 119s 16ms/step - loss: 0.7679 - val_loss: 0.7292\n",
      "Epoch 24/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.7430\n",
      "Epoch 00024: val_loss improved from 0.72922 to 0.70625, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 125s 17ms/step - loss: 0.7430 - val_loss: 0.7063\n",
      "Epoch 25/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.7206\n",
      "Epoch 00025: val_loss improved from 0.70625 to 0.68502, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 126s 17ms/step - loss: 0.7206 - val_loss: 0.6850\n",
      "Epoch 26/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.7009\n",
      "Epoch 00026: val_loss improved from 0.68502 to 0.66689, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 126s 17ms/step - loss: 0.7009 - val_loss: 0.6669\n",
      "Epoch 27/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.6830\n",
      "Epoch 00027: val_loss improved from 0.66689 to 0.65110, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 127s 17ms/step - loss: 0.6830 - val_loss: 0.6511\n",
      "Epoch 28/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.6670\n",
      "Epoch 00028: val_loss improved from 0.65110 to 0.63669, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 126s 17ms/step - loss: 0.6670 - val_loss: 0.6367\n",
      "Epoch 29/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.6528\n",
      "Epoch 00029: val_loss improved from 0.63669 to 0.62346, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 127s 17ms/step - loss: 0.6528 - val_loss: 0.6235\n",
      "Epoch 30/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.6403\n",
      "Epoch 00030: val_loss improved from 0.62346 to 0.61160, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 128s 17ms/step - loss: 0.6403 - val_loss: 0.6116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.6288\n",
      "Epoch 00031: val_loss improved from 0.61160 to 0.60171, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 125s 17ms/step - loss: 0.6288 - val_loss: 0.6017\n",
      "Epoch 32/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.6185\n",
      "Epoch 00032: val_loss improved from 0.60171 to 0.59279, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 129s 17ms/step - loss: 0.6185 - val_loss: 0.5928\n",
      "Epoch 33/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.6097\n",
      "Epoch 00033: val_loss improved from 0.59279 to 0.58371, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 131s 18ms/step - loss: 0.6097 - val_loss: 0.5837\n",
      "Epoch 34/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.6015\n",
      "Epoch 00034: val_loss improved from 0.58371 to 0.57669, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 129s 18ms/step - loss: 0.6015 - val_loss: 0.5767\n",
      "Epoch 35/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.5943\n",
      "Epoch 00035: val_loss improved from 0.57669 to 0.57016, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 132s 18ms/step - loss: 0.5943 - val_loss: 0.5702\n",
      "Epoch 36/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5879\n",
      "Epoch 00036: val_loss improved from 0.57016 to 0.56426, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 136s 18ms/step - loss: 0.5879 - val_loss: 0.5643\n",
      "Epoch 37/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5820\n",
      "Epoch 00037: val_loss improved from 0.56426 to 0.55873, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 134s 18ms/step - loss: 0.5820 - val_loss: 0.5587\n",
      "Epoch 38/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.5770\n",
      "Epoch 00038: val_loss improved from 0.55873 to 0.55445, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 135s 18ms/step - loss: 0.5770 - val_loss: 0.5544\n",
      "Epoch 39/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5722\n",
      "Epoch 00039: val_loss improved from 0.55445 to 0.54990, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 129s 17ms/step - loss: 0.5722 - val_loss: 0.5499\n",
      "Epoch 40/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5677\n",
      "Epoch 00040: val_loss improved from 0.54990 to 0.54578, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5677 - val_loss: 0.5458\n",
      "Epoch 41/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5638\n",
      "Epoch 00041: val_loss improved from 0.54578 to 0.54212, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5638 - val_loss: 0.5421\n",
      "Epoch 42/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.5603\n",
      "Epoch 00042: val_loss improved from 0.54212 to 0.53876, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 16ms/step - loss: 0.5603 - val_loss: 0.5388\n",
      "Epoch 43/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5569\n",
      "Epoch 00043: val_loss improved from 0.53876 to 0.53590, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 123s 17ms/step - loss: 0.5569 - val_loss: 0.5359\n",
      "Epoch 44/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5539\n",
      "Epoch 00044: val_loss improved from 0.53590 to 0.53308, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5539 - val_loss: 0.5331\n",
      "Epoch 45/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.5511\n",
      "Epoch 00045: val_loss improved from 0.53308 to 0.53052, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5511 - val_loss: 0.5305\n",
      "Epoch 46/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5486\n",
      "Epoch 00046: val_loss improved from 0.53052 to 0.52811, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5486 - val_loss: 0.5281\n",
      "Epoch 47/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5463\n",
      "Epoch 00047: val_loss improved from 0.52811 to 0.52595, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5463 - val_loss: 0.5260\n",
      "Epoch 48/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5440\n",
      "Epoch 00048: val_loss improved from 0.52595 to 0.52405, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 120s 16ms/step - loss: 0.5440 - val_loss: 0.5240\n",
      "Epoch 49/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.5420\n",
      "Epoch 00049: val_loss improved from 0.52405 to 0.52213, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 120s 16ms/step - loss: 0.5420 - val_loss: 0.5221\n",
      "Epoch 50/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5402\n",
      "Epoch 00050: val_loss improved from 0.52213 to 0.52019, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5402 - val_loss: 0.5202\n",
      "Epoch 51/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.5385\n",
      "Epoch 00051: val_loss improved from 0.52019 to 0.51867, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 120s 16ms/step - loss: 0.5385 - val_loss: 0.5187\n",
      "Epoch 52/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5367\n",
      "Epoch 00052: val_loss improved from 0.51867 to 0.51697, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 16ms/step - loss: 0.5367 - val_loss: 0.5170\n",
      "Epoch 53/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.5353\n",
      "Epoch 00053: val_loss improved from 0.51697 to 0.51563, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5353 - val_loss: 0.5156\n",
      "Epoch 54/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.5337\n",
      "Epoch 00054: val_loss improved from 0.51563 to 0.51423, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5337 - val_loss: 0.5142\n",
      "Epoch 55/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.5323\n",
      "Epoch 00055: val_loss improved from 0.51423 to 0.51290, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5323 - val_loss: 0.5129\n",
      "Epoch 56/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.5312\n",
      "Epoch 00056: val_loss improved from 0.51290 to 0.51179, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5312 - val_loss: 0.5118\n",
      "Epoch 57/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5300\n",
      "Epoch 00057: val_loss improved from 0.51179 to 0.51058, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 115s 16ms/step - loss: 0.5300 - val_loss: 0.5106\n",
      "Epoch 58/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5289\n",
      "Epoch 00058: val_loss improved from 0.51058 to 0.50959, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 115s 16ms/step - loss: 0.5289 - val_loss: 0.5096\n",
      "Epoch 59/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.5279\n",
      "Epoch 00059: val_loss improved from 0.50959 to 0.50862, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 115s 16ms/step - loss: 0.5279 - val_loss: 0.5086\n",
      "Epoch 60/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.5269\n",
      "Epoch 00060: val_loss improved from 0.50862 to 0.50768, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5269 - val_loss: 0.5077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.5259\n",
      "Epoch 00061: val_loss improved from 0.50768 to 0.50683, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5259 - val_loss: 0.5068\n",
      "Epoch 62/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.5250\n",
      "Epoch 00062: val_loss improved from 0.50683 to 0.50600, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5251 - val_loss: 0.5060\n",
      "Epoch 63/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5241\n",
      "Epoch 00063: val_loss improved from 0.50600 to 0.50518, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5242 - val_loss: 0.5052\n",
      "Epoch 64/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5234\n",
      "Epoch 00064: val_loss improved from 0.50518 to 0.50431, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5234 - val_loss: 0.5043\n",
      "Epoch 65/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5226\n",
      "Epoch 00065: val_loss improved from 0.50431 to 0.50362, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5226 - val_loss: 0.5036\n",
      "Epoch 66/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5219\n",
      "Epoch 00066: val_loss improved from 0.50362 to 0.50285, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5219 - val_loss: 0.5029\n",
      "Epoch 67/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.5212\n",
      "Epoch 00067: val_loss improved from 0.50285 to 0.50219, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 118s 16ms/step - loss: 0.5212 - val_loss: 0.5022\n",
      "Epoch 68/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5205\n",
      "Epoch 00068: val_loss improved from 0.50219 to 0.50155, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 17ms/step - loss: 0.5205 - val_loss: 0.5016\n",
      "Epoch 69/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.5199\n",
      "Epoch 00069: val_loss improved from 0.50155 to 0.50091, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 17ms/step - loss: 0.5199 - val_loss: 0.5009\n",
      "Epoch 70/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5194\n",
      "Epoch 00070: val_loss improved from 0.50091 to 0.50048, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5194 - val_loss: 0.5005\n",
      "Epoch 71/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5188\n",
      "Epoch 00071: val_loss improved from 0.50048 to 0.49981, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5188 - val_loss: 0.4998\n",
      "Epoch 72/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5181\n",
      "Epoch 00072: val_loss improved from 0.49981 to 0.49921, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 123s 17ms/step - loss: 0.5181 - val_loss: 0.4992\n",
      "Epoch 73/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5175\n",
      "Epoch 00073: val_loss improved from 0.49921 to 0.49860, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 16ms/step - loss: 0.5175 - val_loss: 0.4986\n",
      "Epoch 74/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5171\n",
      "Epoch 00074: val_loss improved from 0.49860 to 0.49817, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 17ms/step - loss: 0.5171 - val_loss: 0.4982\n",
      "Epoch 75/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.5165\n",
      "Epoch 00075: val_loss improved from 0.49817 to 0.49767, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5165 - val_loss: 0.4977\n",
      "Epoch 76/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5162\n",
      "Epoch 00076: val_loss improved from 0.49767 to 0.49723, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5162 - val_loss: 0.4972\n",
      "Epoch 77/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.5157\n",
      "Epoch 00077: val_loss improved from 0.49723 to 0.49676, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 120s 16ms/step - loss: 0.5157 - val_loss: 0.4968\n",
      "Epoch 78/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.5152\n",
      "Epoch 00078: val_loss improved from 0.49676 to 0.49640, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5152 - val_loss: 0.4964\n",
      "Epoch 79/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5148\n",
      "Epoch 00079: val_loss improved from 0.49640 to 0.49576, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5148 - val_loss: 0.4958\n",
      "Epoch 80/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.5144\n",
      "Epoch 00080: val_loss improved from 0.49576 to 0.49541, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 16ms/step - loss: 0.5144 - val_loss: 0.4954\n",
      "Epoch 81/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5140\n",
      "Epoch 00081: val_loss improved from 0.49541 to 0.49501, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5140 - val_loss: 0.4950\n",
      "Epoch 82/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5137\n",
      "Epoch 00082: val_loss improved from 0.49501 to 0.49461, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 17ms/step - loss: 0.5137 - val_loss: 0.4946\n",
      "Epoch 83/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5132\n",
      "Epoch 00083: val_loss improved from 0.49461 to 0.49424, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 17ms/step - loss: 0.5132 - val_loss: 0.4942\n",
      "Epoch 84/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.5129\n",
      "Epoch 00084: val_loss improved from 0.49424 to 0.49377, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5129 - val_loss: 0.4938\n",
      "Epoch 85/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5125\n",
      "Epoch 00085: val_loss improved from 0.49377 to 0.49352, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 115s 16ms/step - loss: 0.5125 - val_loss: 0.4935\n",
      "Epoch 86/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5124\n",
      "Epoch 00086: val_loss improved from 0.49352 to 0.49321, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5124 - val_loss: 0.4932\n",
      "Epoch 87/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5118\n",
      "Epoch 00087: val_loss improved from 0.49321 to 0.49277, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5118 - val_loss: 0.4928\n",
      "Epoch 88/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5117\n",
      "Epoch 00088: val_loss improved from 0.49277 to 0.49243, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5117 - val_loss: 0.4924\n",
      "Epoch 89/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5113\n",
      "Epoch 00089: val_loss improved from 0.49243 to 0.49211, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 117s 16ms/step - loss: 0.5113 - val_loss: 0.4921\n",
      "Epoch 90/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.5111\n",
      "Epoch 00090: val_loss improved from 0.49211 to 0.49182, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 115s 16ms/step - loss: 0.5111 - val_loss: 0.4918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5107\n",
      "Epoch 00091: val_loss improved from 0.49182 to 0.49154, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5107 - val_loss: 0.4915\n",
      "Epoch 92/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5104\n",
      "Epoch 00092: val_loss improved from 0.49154 to 0.49118, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5104 - val_loss: 0.4912\n",
      "Epoch 93/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.5101\n",
      "Epoch 00093: val_loss improved from 0.49118 to 0.49097, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5101 - val_loss: 0.4910\n",
      "Epoch 94/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5098\n",
      "Epoch 00094: val_loss improved from 0.49097 to 0.49068, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 116s 16ms/step - loss: 0.5099 - val_loss: 0.4907\n",
      "Epoch 95/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.5095\n",
      "Epoch 00095: val_loss improved from 0.49068 to 0.49036, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5095 - val_loss: 0.4904\n",
      "Epoch 96/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5093\n",
      "Epoch 00096: val_loss improved from 0.49036 to 0.49017, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 17ms/step - loss: 0.5093 - val_loss: 0.4902\n",
      "Epoch 97/100\n",
      "7375/7377 [============================>.] - ETA: 0s - loss: 0.5091\n",
      "Epoch 00097: val_loss improved from 0.49017 to 0.48977, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 120s 16ms/step - loss: 0.5091 - val_loss: 0.4898\n",
      "Epoch 98/100\n",
      "7376/7377 [============================>.] - ETA: 0s - loss: 0.5089\n",
      "Epoch 00098: val_loss improved from 0.48977 to 0.48951, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 16ms/step - loss: 0.5089 - val_loss: 0.4895\n",
      "Epoch 99/100\n",
      "7377/7377 [==============================] - ETA: 0s - loss: 0.5085\n",
      "Epoch 00099: val_loss improved from 0.48951 to 0.48927, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 122s 17ms/step - loss: 0.5085 - val_loss: 0.4893\n",
      "Epoch 100/100\n",
      "7374/7377 [============================>.] - ETA: 0s - loss: 0.5083\n",
      "Epoch 00100: val_loss improved from 0.48927 to 0.48897, saving model to model/autoencoder_991_001.h5\n",
      "7377/7377 [==============================] - 121s 16ms/step - loss: 0.5083 - val_loss: 0.4890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc583274748>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.model.compile(optimizer = optimizers.Adam(lr=1e-5), loss=losses.CategoricalCrossentropy())\n",
    "e.model.fit(train_data_onehot,train_data_onehot,\n",
    "            batch_size= 5,epochs=100,\n",
    "            shuffle=True,\n",
    "            validation_data=(valid_data_onehot, valid_data_onehot),\n",
    "            callbacks=[reduce_lr, e_s,saveBestModel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'embedding'\n",
    "intermediate_layer_model = Model(inputs=e.model.input,\n",
    "                                 outputs=e.model.get_layer(layer_name).output)\n",
    "#intermediate_output = intermediate_layer_model.predict(data)\n",
    "intermediate_layer_model.save('model/autoencoder_embedding_991_001.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from obesity.model_evaluation import metric_array,show_train_history\n",
    "\n",
    "show_train_history(e.model.history ,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "autoencoder_path = 'model/autoencoder_991_001.h5'\n",
    "e = load_model(autoencoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(e(valid_data_onehot[1].reshape(1,-1,11))[0].numpy().transpose()[:,:100])\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAABGCAYAAADVTc87AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAHVklEQVR4nO3dX6gc5RnH8e+vJw2tFqrWIDaJNdKghIKmR6ylpRT/QKyiXkg1VJBiyY2iLZWS9q4XhRZK/1yUwkHTeiHakgqGIpaigr0oIec0F2pSNaS1OSEag01belEbfHoxo2ezPbtndmZ2Zt6d3wcOZ2d2dubdd555ePfdd95VRGBmZun5QNsFMDOzcpzAzcwS5QRuZpYoJ3Azs0Q5gZuZJcoJ3MwsUZUSuKQdkl6RdETS7roKZWZma1PZceCS5oBXgRuBZeAAsDMiDtVXPDMzG2VdhddeAxyJiKMAkp4AbgNGJnBJvmvIrAbz8/PvP15aWmqxJNaQUxGxYXhllQS+ETg2sLwMfKbC/sysoMXFxfcfS2qxJNaQ11dbWSWBFyJpF7Br2scxM+ubKgn8OLB5YHlTvu4sEbEALMDZXSjj+t4HWxTD25VpbQzuY5ZaK114X0XPo60YF9NFz2nRuu1CjExD199XU+WrMgrlALBV0hZJ64G7gH31FMvMzNZSugUeEWck3Q/8DpgD9kTEy7WVzMzMxqrUBx4RTwNP11QWMzObwNS/xBylaL/Q8HZl+pa62EdWhy68ry6UITV19G3XcayUdf19NVU+30pvZpYoJ3Azs0S11oVS1qwMlyszjLLsey+6Dw8JNKh/6O7wPtoaAlh26HKR17TFLXAzs0Q5gZuZJSq5LpS2tDU6oI7j9n20jk1m2jHXVpzN4nXgFriZWaKcwM3MEuUEbmaWqE72gZcZ9lbHHZs2WtX6rGNoWpn9TWPWy1F1Uffws7rrrKyUrrOu1NmgsnFRpG7dAjczS5QTuJlZojrZhVLHcJ8ufHSaJVXrs+vDMCcp36htZ3UiqpSus66VB8qXqcjr3AI3M0uUE7iZWaKcwM3MEtXJPvC2lJ2Nr45hj23o4pCr1HTtnLap7uGGTV5XVctX5dhVuAVuZpYoJ3Azs0Q12oUyPz/P4uIi0I27yobVMdynjv0XvdOvzHHb+rg5bh+Dxn30LrpdHR/Ri9ZnF7tNqv6AxySvKVoXVe+UHaeO7pUy57Huc1+mS8YtcDOzRDmBm5klSkUnWqnlYFJzBzMzmx1LEXH18Eq3wM3MErVmApe0R9JJSS8NrLtA0u8lvZb/P3+6xTQzs2FFWuC/BHYMrdsNPBsRW4Fn82UzM2vQmgk8Il4A3h5afRvwaP74UeD2mss1sYg468/aV+Z81HEeU4uDouUdtV3ROkv5Gkmh7G2Ur+w48Isi4kT++A3golEbStoF7Cp5HDMzG6HyjTwREeNGl0TEArAAHoViZlansgn8TUkXR8QJSRcDJwu+7hTw7/x/rbp4R1wBFzKFuuiKCc/JhcCpOs5jarGwSnlXjYuqPySRWr3kaouLaZtyGT+x2sqyCXwfcA/w/fz/U0VeFBEbJC2uNp6xj1wXK1wXK1wXK1wX4xUZRvg48EfgcknLku4lS9w3SnoNuCFfNjOzBq3ZAo+InSOeur7mspiZ2QTauBNzoYVjdpXrYoXrYoXrYoXrYoxG50IxM7P6eC4UM7NENZrAJe2Q9IqkI5J6dfu9pM2Snpd0SNLLkh7M1/d2XhlJc5IOSvptvrxF0v48Pn4laX3bZWyCpPMk7ZX0Z0mHJX22r3Eh6Rv59fGSpMclfaivcVFEYwlc0hzwM+AmYBuwU9K2po7fAWeAb0bENuBa4L78/fd5XpkHgcMDyz8AfhwRnwT+DtzbSqma91PgmYi4AriSrE56FxeSNgIPAFdHxKeAOeAu+hsXa2qyBX4NcCQijkbEO8ATZHOq9EJEnIiIP+WP/0V2kW6kg/PKNEHSJuBm4OF8WcB1wN58k17UhaSPAl8AHgGIiHci4jQ9jQuykXEflrQOOAc4QQ/joqgmE/hG4NjA8nK+rnckXQpsB/YzwbwyM+YnwLeAd/PljwGnI+JMvtyX+NgCvAX8Iu9OeljSufQwLiLiOPBD4G9kifsfwBL9jItC/CVmwyR9BPgN8PWI+Ofgc5ENCZr5YUGSbgFORsRS22XpgHXAp4GfR8R2sqkmzuou6VFcnE/2yWML8HHgXP5/Kmsb0GQCPw5sHljelK/rDUkfJEvej0XEk/nqN/P5ZJhwXpmUfQ64VdJfybrSriPrBz4v/+gM/YmPZWA5Ivbny3vJEnof4+IG4C8R8VZE/Bd4kixW+hgXhTSZwA8AW/NvlNeTfTmxr8Hjtyrv430EOBwRPxp46r15ZWCCeWVSFhHfjohNEXEpWRw8FxFfAZ4H7sg360tdvAEck3R5vup64BA9jAuyrpNrJZ2TXy/v1UXv4qKopn/U+EtkfZ9zwJ6I+F5jB2+ZpM8DfwBeZKXf9ztk/eC/Bi4BXge+HBHDP6AxsyR9EXgoIm6RdBlZi/wC4CBwd0T8p83yNUHSVWRf5q4HjgJfJWtc9S4uJH0XuJNs1NZB4Gtkfd69i4sifCemmVmi/CWmmVminMDNzBLlBG5mligncDOzRDmBm5klygnczCxRTuBmZolyAjczS9T/AICO7PWGsHaLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(valid_data_onehot[1].reshape(1,-1,11)[0].transpose()[:,:100])\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.40000e+01, 6.10000e+01, 5.20000e+01, 7.10000e+01, 7.50000e+01,\n",
       "        7.40000e+01, 7.60000e+01, 8.90000e+01, 7.70000e+01, 1.22000e+02,\n",
       "        9.30000e+01, 9.50000e+01, 1.06000e+02, 1.29000e+02, 1.14000e+02,\n",
       "        1.56000e+02, 1.66000e+02, 1.27000e+02, 1.54000e+02, 1.85000e+02,\n",
       "        1.89000e+02, 2.59000e+02, 2.73000e+02, 3.16000e+02, 3.13000e+02,\n",
       "        2.37000e+02, 1.84000e+02, 1.27000e+02, 1.13000e+02, 1.35000e+02,\n",
       "        1.27000e+02, 9.90000e+01, 1.32000e+02, 1.21000e+02, 1.50000e+02,\n",
       "        1.48000e+02, 1.48000e+02, 1.41000e+02, 1.83000e+02, 1.64000e+02,\n",
       "        2.07000e+02, 2.06000e+02, 2.24000e+02, 2.97000e+02, 3.94000e+02,\n",
       "        4.06000e+02, 6.22000e+02, 8.64000e+02, 9.87000e+02, 2.02300e+03,\n",
       "        1.07971e+05, 2.39500e+03, 1.48000e+03, 1.07700e+03, 7.85000e+02,\n",
       "        6.69000e+02, 5.80000e+02, 4.87000e+02, 4.99000e+02, 4.15000e+02,\n",
       "        3.95000e+02, 3.62000e+02, 3.40000e+02, 3.34000e+02, 3.34000e+02,\n",
       "        2.80000e+02, 2.93000e+02, 3.36000e+02, 3.22000e+02, 2.75000e+02,\n",
       "        2.84000e+02, 2.83000e+02, 3.42000e+02, 3.54000e+02, 3.14000e+02,\n",
       "        2.39000e+02, 1.53000e+02, 9.90000e+01, 8.10000e+01, 6.40000e+01,\n",
       "        6.90000e+01, 6.60000e+01, 7.70000e+01, 4.10000e+01, 5.90000e+01,\n",
       "        5.20000e+01, 4.70000e+01, 4.40000e+01, 3.20000e+01, 5.30000e+01,\n",
       "        4.00000e+01, 4.00000e+01, 3.60000e+01, 3.60000e+01, 3.60000e+01,\n",
       "        3.70000e+01, 3.80000e+01, 3.60000e+01, 2.90000e+01, 9.00000e+00]),\n",
       " array([-0.9986351 , -0.97870487, -0.9587746 , -0.9388444 , -0.91891414,\n",
       "        -0.89898396, -0.8790537 , -0.85912347, -0.8391932 , -0.819263  ,\n",
       "        -0.79933274, -0.7794025 , -0.75947225, -0.73954207, -0.7196118 ,\n",
       "        -0.6996816 , -0.67975134, -0.6598211 , -0.63989085, -0.6199606 ,\n",
       "        -0.60003036, -0.5801002 , -0.56016994, -0.5402397 , -0.52030945,\n",
       "        -0.5003792 , -0.48044896, -0.46051872, -0.4405885 , -0.42065826,\n",
       "        -0.40072802, -0.38079777, -0.36086756, -0.34093732, -0.32100707,\n",
       "        -0.30107683, -0.28114662, -0.26121637, -0.24128613, -0.2213559 ,\n",
       "        -0.20142566, -0.18149543, -0.16156518, -0.14163496, -0.12170471,\n",
       "        -0.10177448, -0.08184424, -0.061914  , -0.04198377, -0.02205353,\n",
       "        -0.0021233 ,  0.01780694,  0.03773718,  0.05766741,  0.07759765,\n",
       "         0.09752788,  0.11745812,  0.13738836,  0.15731859,  0.17724884,\n",
       "         0.19717906,  0.21710931,  0.23703954,  0.25696978,  0.27690002,\n",
       "         0.29683024,  0.31676048,  0.33669072,  0.35662097,  0.37655118,\n",
       "         0.39648142,  0.41641167,  0.4363419 ,  0.45627213,  0.47620237,\n",
       "         0.4961326 ,  0.51606286,  0.5359931 ,  0.55592334,  0.5758536 ,\n",
       "         0.59578377,  0.615714  ,  0.63564426,  0.6555745 ,  0.67550474,\n",
       "         0.695435  ,  0.71536523,  0.7352955 ,  0.75522566,  0.7751559 ,\n",
       "         0.79508615,  0.8150164 ,  0.83494663,  0.8548769 ,  0.8748071 ,\n",
       "         0.89473736,  0.91466755,  0.9345978 ,  0.95452803,  0.9744583 ,\n",
       "         0.9943885 ], dtype=float32),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = e(train_data_onehot[1].reshape(1,-1,11)).numpy().reshape(-1)\n",
    "a = train_data_onehot[1].reshape(-1)\n",
    "plt.hist(p-a,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
